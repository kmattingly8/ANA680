# ANA680: Machine Learning Deployment

Welcome to my repository for the **ANA680: Machine Learning Deployment** course. This repository contains all the assignments and projects that I have completed as part of this course. Below you will find important information about the repository and how to navigate the assignments.

---

## Table of Contents

- [Course Overview](#course-overview)
- [Assignments](#assignments)
  - [Assignment 2a: <Building Classification Models>](#Building Classification Models)
  - [Assignment 2b: <Design a Three-Layered ANN Classifier>](#Design a Three-Layered ANN Classifier)
- [Technologies Used](#technologies-used)
- [Acknowledgements](#acknowledgements)

---

## Course Overview

This course focuses on the deployment of machine learning models. It covers topics such as model deployment strategies, using cloud platforms, version control, CI/CD pipelines, and integrating machine learning models into real-world applications. By completing the assignments in this repository, I gained hands-on experience with these key deployment concepts.

---

## Assignments

### Assignment 2a: <Building Classification Models>
- **Description**: Using a breast cancer data set, build the following types of classification models: Logistic Regression, KNN, Linear SVM, RBF SVM, Naive Bayes, Decision Tree, Random Forest, and XGBoost. Evaluate the models and provide accuracy and confusion matrices for each.

### Assignment 2b: <Design a Three-Layered ANN Classifier>
- **Description**: Build a three-layered ANN classifier model that predicts whether customers will churn.


---

## Technologies Used

This course used various technologies and tools, including but not limited to:

- **Python**: For coding and model building
- **Scikit-learn**: For machine learning models and model evaluation
- **XGBoost**: For advanced gradient boosting models
- **TensorFlow**: For building and deploying deep learning models
- **Docker**: For containerizing models and ensuring consistency across environments
- **Flask/FastAPI**: For building APIs to serve machine learning models
- **AWS/GCP**: For cloud-based model deployment and storage
- **GitHub Actions**: For Continuous Integration/Continuous Deployment (CI/CD) automation
- **Jupyter Notebooks**: For interactive data exploration and analysis
